{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineární klasifikace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Úkolem cvičení je naprogramovat lineární klasifikátor, který bude rozpoznávat objekty z datasetu CIFAR-10. **Využijeme k tomu knihovnu pytorch.**\n",
    "\n",
    "Kromě známých knihoven numpy, matplotlib a torch budeme potřebovat následující:\n",
    "- torchvision ... rozšiřující pytorch balík pro pytorch obsahující datasety, funkce pro zpracování obrázků a předtrénované modely konvolučních sítí\n",
    "- tqdm ... vykresluje během výpočtů progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Způsob načítání dat kompletně závisí na způsobu, jakým byla uložena. Zde použijeme populární dataset CIFAR-10, který často slouží jako základní benchmark pro porovnání přínosu nových algoritmů vůči stávajícím. Úkolem je klasifikace obrázků do jedné z 10 tříd.\n",
    "\n",
    "Balík torchvision podporuje některé znamé datasety, mezi něž patří i CIFAR-10. Nemusíme tedy data stahovat z internetu manuálně, torchvision za nás vše obstará automaticky. Data uložíme do adresáře `./data`. Všimněme si flagu `train=True`, který říká, že se má načíst trénovací množina datasetu CIFAR-10 (soubory `data_batch_*`).\n",
    "\n",
    "Tenhle komentář změním."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výsledný objekt se chová jako `list`, byť není jeho odvozeninou (subclass). Indexuje tedy prvky od nuly, má definovanou délku skrze `__len__` a podporuje `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zavola `__len__`\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zavola `__getitem__` s parametrem (indexem) 5\n",
    "trainset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak vidíme, 6. prvek datasetu je *dvojice* sestávající z obrázku a jeho indexu třídy (label, target). Obrázek je defaultně navrácen jako typ `Image` knihovny Pillow (Python Imaging Library, PIL). Pokud je výstupem buňky objekt tohoto typu, jupyter notebook to rozpozná a zobrazí ho jako obrázek. `Image` má totiž definovanou metodu `__html__`, jíž dá notebook přednost před obvyklým `__repr__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset[5][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objekt CIFAR datasetu obsahuje i textový popis tříd ve formě pole (`list`) názvů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 6. prvku\n",
    "trainset.classes[trainset[5][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Všechny obrázky CIFAR datasetu jsou uloženy v atributu `.train_data`, což je 4D `numpy.ndarray`. První dimenze odpovídá jednotlivým obrázkům, další pak řádkům, sloupcům a kanálům (RGB), tedy $50000 \\times 32 \\times 32 \\times 3$. Hodnoty jsou uloženy jako datový typ `uint8`, tedy v rozsahu 0...255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainset.data), trainset.data.shape, trainset.data.dtype, trainset.data.min(), trainset.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobně všechny labely jsou uloženy v `.targets`, což je `list` čísel (`int`) o délce počtu obrázků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainset.targets), len(trainset.targets), type(trainset.targets[0]), min(trainset.targets), max(trainset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud chceme obrázků vykreslit více najednou, vhodnější použít matplotlib (pyplot). Pro každou třídu vykreslíme po sloupcích 10 příkladů, abychom viděli, jak data vlastně vypadají."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, cls in enumerate(trainset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(trainset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(trainset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testovací/validační data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testovací data ze souboru `test_batch` načteme stejně jako trénovací, pouze tentokrát nastavíme flag `train` na hodnotu `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(testset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(testset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(testset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matice trénovacích a validačních dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jelikož použijeme jednoduchý lineární klasifikátor, data **převedeme do maticové formy**, ve které každý řádek reprezentuje jeden obrázek. Pro lepší numerické chování data navíc z rozsahu `0...255` a typu `uint8` převedeme do rozsahu `0...1` a datového typu s plovoucí řádovou čárkou.\n",
    "\n",
    "### Validační vs testovací množiny\n",
    "\n",
    "Testovací sada, která je v případě CIFAR-10 obsažena v souboru `cifar-10-batches-py/test_batch`, by správně neměla být používána pro validaci, tj. volbu modelu a ladění hyperparametrů, ale pouze pro odhad úspěšnosti natrénovaného klasifikátoru na neviděných datech. Pokud použijeme testovací data pro validaci, efektivně tím využíváme informaci v nich obsaženou pro učení modelu. Takto dosažená skóre bychom proto neměli uvádět jako odhad úspěšnosti na neviděných datech, může být totiž příliš optimistický."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevedeme na pytorch tensor\n",
    "X_train = torch.tensor(trainset.data)\n",
    "\n",
    "# na vychozi datovy typ (float nebo double, lze menit) a do rozsahu 0...1\n",
    "X_train = X_train.to(torch.get_default_dtype()) / 255.\n",
    "\n",
    "# reshape na matici s obrazky na radcich\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "X_train.dtype, X_train.shape, X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labely** trénovacích dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(trainset.targets)\n",
    "y_train.dtype, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matice **validačních** dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevedeme na pytorch tensor\n",
    "X_valid = torch.tensor(testset.data)\n",
    "\n",
    "# na vychozi datovy typ (float nebo double, lze menit) a do rozsahu 0...1\n",
    "X_valid = X_valid.to(torch.get_default_dtype()) / 255.\n",
    "\n",
    "# reshape na matici s obrazky na radcich\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
    "\n",
    "X_valid.dtype, X_valid.shape, X_valid.min(), X_valid.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labely** validačních dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = torch.tensor(testset.targets)\n",
    "y_valid.dtype, y_valid.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax (logistická regrese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Připomeňme, že logistická regrese je jednoduchý lineární klasifikátor s parametry:\n",
    "\n",
    "- váhová matice $W$\n",
    "  - rozměr `rozměr_vstupu x počet_tříd`\n",
    "  - inicializujeme na malé náhodné hodnoty\n",
    "  - v kódu označíme jako `W_smax` (váhy softmaxu)\n",
    "- bias vektor $b$\n",
    "  - rozměr `počet_tříd`\n",
    "  - inicializujeme na vektor nul\n",
    "  - v kódu označíme jako `b_smax` (bias softmaxu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "W_smax = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "W_smax.dtype, W_smax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "b_smax = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "b_smax.dtype, b_smax.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trénování metodou online SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dopředný průchod\n",
    "1. Pokud máme na vstupu *jeden* obrázek $x$, vektor lineárního skóre pro jednotlivé třídy je\n",
    "$$ s \\leftarrow W x + b $$\n",
    "a tedy $s \\in \\mathbb{R}^C$, kde $C$ značí celkový počet tříd.\n",
    "\n",
    "2. Vektor skóre $s$ dále prochází softmaxem. Získáme vektor $p$, ve kterém $i$-tý prvek značí pravděpodobnost, že $x$ patří do třídy $i$.\n",
    "$$ p \\leftarrow \\frac{\\exp{s}}{\\sum_{c=0}^{C-1}\\exp{s_c}} $$\n",
    "Výsledné $p$ má tedy stejný rozměr jako $s$ a platí $\\sum_{c}p_c=1$.\n",
    "\n",
    "3. Zda a jak moc byla predikce správná určí kriteriální funkce (loss), tzv. cross entropy, která ve speciálním případě klasifikace do jedné z $C$ tříd má tvar\n",
    "$$L \\leftarrow -\\log p_y$$\n",
    "kde $y\\in\\{1,\\ldots,C\\}$ je index třídy, do které obrázek ve skutečnosti patří (label/target obrázku).\n",
    "\n",
    "##### Regularizace\n",
    "\n",
    "Regularizace penalizuje příliš velké hodnoty vah $W$. Nejčastěji se setkáme s typem L2, u nějž k výsledné hodnotě lossu přičítáme dodatečný člen\n",
    "$$\\lambda\\sum_{ij}w_{ij}^2$$\n",
    "kde $w_{ij}$ je váha na $i$-tém řádku a $j$-tém sloupci matice $W$ a $\\lambda$ je hyperparametr vyjadřující váhu regularizace (v kódu je $\\lambda$ označená jako proměnná `l2_decay`).\n",
    "\n",
    "Pro lepší monitoring hodnoty lossu **regularizaci nepřičítejte**, ale držte ji zvlášť v proměnné `l2_val`.\n",
    "\n",
    "#### Zpětný průchod\n",
    "1. Vzorec pro gradient na $c$-tý řádek váhové *matice* je (řádek pro správnou třídu se od ostatních liší)\n",
    "$$ \\frac{\\partial L}{\\partial w_c} \\leftarrow \\left(p_c - \\boldsymbol{1}(c=y)\\right) x^\\top $$\n",
    "\n",
    "2. Gradient na $c$-tý prvek bias *vektoru* (prvek pro správnou třídu se od ostatních liší)\n",
    "$$ \\frac{\\partial L}{\\partial b_c} \\leftarrow p_c - \\boldsymbol{1}(c=y) $$\n",
    "\n",
    "##### Regularizace\n",
    "\n",
    "Pokud používáme regularizaci vah $W$, ještě před updatem parametrů $W$ a $b$ upravíme ${\\partial L} / {\\partial W}$ gradientem regularizačního členu (ten zvládnete sami). Nezapomeňte na váhu regularizace $\\lambda$.\n",
    "\n",
    "#### Gradient descent update \n",
    "\n",
    "1. Update vah $W$\n",
    "$$ W \\leftarrow W - \\gamma \\frac{\\partial L}{\\partial W} $$\n",
    "kde $\\gamma$ je velikost kroku gradient descentu (learning rate)\n",
    "\n",
    "2. Update biasu $b$\n",
    "$$ b \\leftarrow b - \\gamma \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "### Poznámky\n",
    "\n",
    "- Popsaný způsob a kostra kódu odpovídá trénování online variantou gradient descentu (stochastic gradient descent, SGD), tzn. update parametrů následuje po každém vstupním vektoru, nikoliv po zpracování všech dat.\n",
    "- Ve vzorečcích se pracuje s vektorem $x$ jako se sloupcem, ale data v `X_train` jsou po řádcích a matice vah $W$ má rozměr `rozměr_vstupu x počet_tříd`. V kódu proto budou výpočty transponované, tj. $s = x W + b$ a vzorec pro gradient na $c$-tý *řádek* matice $W$ bude ve skutečnosti vzorec na $c$-tý sloupec!\n",
    "  \n",
    "  \"Proboha proč?\", ptáte se? Teorie vychází ze zavedené konvence v lineární algebře, kde jsou vektory uvažovány jako sloupcové a strojové učení tímto způsobem popisuje i většina dopstupné literatury. Pro zachování \"kompatibility\" materiálů tak postpujejme i zde. Tuto konvenci kdysi dávno převzal jazyk Fortran a v návaznosti na něj i MATLAB, a proto mají tyto jazyky matice uložené po sloupcích. V jazycích jako Python (potažmo v knihovnách numpy a pytorch) jsou však matice tzv. row-major, a tedy daty uloženými typicky po řádcích, a bez transpozice rovnic by se musela transponovat data $x$, což by bylo výpočetně neefektivní.\n",
    "  \n",
    "- Většina operací (např. funkce `argmax`) v pytorchi vrací `torch.tensor`, i když je výsledkem jediné reálné číslo. V takovém případě lze obvykle převést na pythonovský built-in typ jednoduše jako např. `int(pytorch_tensor)`.\n",
    "\n",
    "- Odlaďte trénovací cyklus nejprve pro `num_iters = 1`, pak teprve spusťte na velký počet iterací (např. roven počtu trénovacích obrázků = 1 epocha). Pokaždé, když něco selže, sledujte hodnoty a tvar matic (vektorů) skóre, vah apod. v jednotlivých krocích tak, že si vytvoříte novou buňku a prozkoumáte, co se s nimi děje.\n",
    "\n",
    "- Hyperparametry $\\gamma$ (`learning_rate`) a $\\lambda$ (`l2_decay`) nastavte na malé hodnoty $\\ll 1$ a optimalizujte tak, abyste dosáhli co nejlepšího skóre na validačních datech. Krok gradient descentu `learning_rate` můžete při opakovaných průchodech daty (epochy) postupně snižovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparametry\n",
    "learning_rate = \n",
    "l2_decay = \n",
    "num_iters = \n",
    "\n",
    "# akumulator\n",
    "num_correct = 0\n",
    "loss = 0.\n",
    "l2_val = 0.\n",
    "\n",
    "# hlavni trenovaci cyklus\n",
    "pb = tqdm.tnrange(num_iters)\n",
    "for n in pb:\n",
    "    # obrazek vybereme nahodne\n",
    "    idx = int(torch.randint(X_train.shape[0], (1,)))\n",
    "    \n",
    "    # ziskame data\n",
    "    xn = X_train[idx]\n",
    "    yn = y_train[idx]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    prob = \n",
    "    loss +=   # neustale se pricita, aby slo jednoduse spocitat prumer pro report dole\n",
    "    l2_val +=   # dtto\n",
    "    \n",
    "    # gradient na vahy\n",
    "    dscore = \n",
    "    dW = \n",
    "    \n",
    "    # gradient na bias\n",
    "    db = \n",
    "    \n",
    "    # regularizace (volitelna; modifikuje gradient na vahy)\n",
    "    dW += \n",
    "    \n",
    "    # update parametru\n",
    "    W_smax \n",
    "    b_smax \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "    \n",
    "    # prubezny vypis\n",
    "    if n % 100 == 0:\n",
    "        pb.set_postfix(loss='{:.3f}'.format(float(loss / (n + 1))), acc='{:.3f}'.format(num_correct / (n + 1)))\n",
    "\n",
    "print('train accuracy: {}/{} = {:.1f} %'.format(num_correct, n, 100. * num_correct / n))\n",
    "print(float(loss) / n, float(l2_val) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace\n",
    "\n",
    "\n",
    "Natrénovaný klasifikátor ověříme na validační (development) množině. Ideálně bychom měli dosáhnout stejné úspěšnosti jako na trénovací sadě, pravděpodobně tomu tak ale nebude. Proč?\n",
    "\n",
    "**Postup je jednodušší než v případě trénování:**\n",
    "1. Dopředný průchod\n",
    "$$ s \\leftarrow W x + b $$\n",
    "\n",
    "2. Není třeba počítat pravděpodobnosti. Softmax pouze znormalizuje skóre tak, aby výsledná čísla tvořila rozdělení pravděpodobnosti. Pokud je ve vektoru $s$ max. hodnota na pozici $i$, pak bude $i$-tý prvek max. i ve vektoru $p$. Stačí tedy porovnat index $i$ s labelem obrázku $y$ a pokud se rovnají, je predikce správná, jinak ne. Výsledné skóre pak bude podíl správně klasifikovaných obrázků vůči celkovému počtu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in tqdm.tnrange(X_valid.shape[0]):   \n",
    "    # ziskame data\n",
    "    xn = X_valid[n]\n",
    "    yn = y_valid[n]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "\n",
    "print('val accuracy: {}/{} = {:.1f} %'.format(num_correct, n, 100. * num_correct / n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weston-Watkins SVM\n",
    "\n",
    "Jak jsme si ukázali v přednášce, SVM je softmaxu velmi podobné. Z pohledu neuronových sítí se liší pouze způsobem výpočtu lossu - místo cross entropy použijeme hinge loss definovaný jako\n",
    "$$L = \\sum_{c\\ne y}\\max(0, 1 + s_c - s_y)$$\n",
    "kde $s$ je vektor lineárních skóre $s=Wx + b$.\n",
    "\n",
    "Gradient na váhy pak je\n",
    "$$\\frac{\\partial L}{\\partial w_y} = -\\sum_{c\\ne y}\\boldsymbol{1}(1 + s_c - s_y > 0)x$$\n",
    "$$\\frac{\\partial L}{\\partial w_{c\\ne y}} = \\boldsymbol{1}(1 + s_c - s_y > 0)x$$\n",
    "a pro biasy podobně, pouze bez násobení $x$ (na konci)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "W_svm = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "W_svm.dtype, W_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "b_svm = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "b_svm.dtype, b_svm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trénování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# hyperparametry\n",
    "learning_rate = \n",
    "l2_decay = \n",
    "num_iters = \n",
    "\n",
    "# akumulator\n",
    "num_correct = 0\n",
    "loss = 0.\n",
    "l2_val = 0.\n",
    "\n",
    "# hlavni trenovaci cyklus\n",
    "pb = tqdm.tnrange(num_iters)\n",
    "for n in pb:\n",
    "    # obrazek vybereme nahodne\n",
    "    idx = int(torch.randint(X_train.shape[0], (1,)))\n",
    "    \n",
    "    # ziskame data\n",
    "    xn = X_train[idx]\n",
    "    yn = y_train[idx]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    margin = \n",
    "    loss += \n",
    "    l2_val += \n",
    "    \n",
    "    # gradient na bias\n",
    "    db = \n",
    "    \n",
    "    # gradient na vahy\n",
    "    dW = \n",
    "    \n",
    "    # regularizace (modifikuje gradient na vahy)\n",
    "    dW += \n",
    "    \n",
    "    # update parametru\n",
    "    W_svm\n",
    "    b_svm\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "    \n",
    "    # prubezny vypis\n",
    "    if n % 100 == 0:\n",
    "        pb.set_postfix(loss='{:.3f}'.format(float(loss / (n + 1))), acc='{:.3f}'.format(num_correct / (n + 1)))\n",
    "\n",
    "print('train accuracy: {}/{} = {:.1f} %'.format(num_correct, num_iters, 100. * num_correct / num_iters))\n",
    "print(float(loss) / num_iters, float(l2_val) / num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in tqdm.tnrange(X_valid.shape[0]):   \n",
    "    # ziskame data\n",
    "    xn = X_valid[n]\n",
    "    yn = y_valid[n]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "\n",
    "print('val accuracy: {}/{} = {:.1f} %'.format(num_correct, X_valid.shape[0], 100. * num_correct / X_valid.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
